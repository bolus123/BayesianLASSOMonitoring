#' result <- GibbsRFLSM(Y, H = H, q = q, nsim = nsim, burnin = burnin)
#'
#' RSS(Y, result$Phi, result$Mu)
#'
RSS <- function(Y, Phi, Mu) {
T <- length(Y)
q <- dim(Phi)[1]
nsim <- dim(Phi)[2]
ee <- matrix(NA, nrow = T - q, ncol = nsim)
rss <- rep(0, nsim)
for (ii in seq(nsim)) {
V <- matrix(Y, ncol = 1) - Mu[, ii]
Vas <- getV(V, q)
V <- V[-c(1:q)]
Vas <- Vas[-c(1:q), ]
ee[, ii] <- V - Vas %*% Phi[, ii]
rss[ii] <- sum(ee[, ii] ^ 2)
}
rss
}
#' obtain the log likelihood
#'
#' @param Y is a vector
#' @param Phi is the coefficient
#' @param Mu is the mean
#' @param sigma2 is the variance
#' @export
#' @examples
#' nsim <- 100
#' burnin <- 100
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM(Y, H = H, q = q, nsim = nsim, burnin = burnin)
#'
#' ll(Y, result$Phi, result$Mu, result$sigma2)
#'
ll <- function(Y, Phi, Mu, sigma2) {
T <- length(Y)
q <- dim(Phi)[1]
nsim <- length(sigma2)
ll <- matrix(NA, nrow = T - q, ncol = nsim)
for (ii in seq(nsim)) {
V <- matrix(Y, ncol = 1) - Mu[, ii]
Vas <- getV(V, q)
V <- V[-c(1:q)]
Vas <- Vas[-c(1:q), ]
resi <- V - Vas %*% Phi[, ii]
ll[, ii] <- dnorm(resi, mean = 0, sd = sqrt(sigma2[ii]), log = TRUE)
}
ll
}
fdelta <- function(alpha, lambda0, pi0, lambda1, pi1) {
a <- sqrt(1 - sum(alpha ^ 2)) / (1 - sum(alpha))
d1 <- (1 - pi1) * lambda1 /
sqrt(lambda1 * (1 - pi1) * (1 + pi1 * lambda1))
d0 <- (1 - pi0) * lambda0 /
sqrt(lambda0 * (1 - pi0) * (1 + pi0 * lambda0))
a * (d1 - d0)
}
flambda1 <- function(delta, alpha, lambda0, pi0, pi1 = pi0, interval = c(1e-10, 1000)) {
rootfinding <- function(lambda1, delta, alpha, lambda0, pi0, pi1) {
tmp <- fdelta(alpha, lambda0, pi0, lambda1, pi1)
#cat("tmp:", tmp, "lambda1:", lambda1, "\n")
delta - tmp
}
uniroot(rootfinding, interval = interval, delta = delta,
alpha = alpha,
lambda0 = lambda0, pi0 = pi0, pi1 = pi1)$root
}
fpi1 <- function(delta, alpha, lambda0, pi0, lambda1 = lambda0,
interval = c(1e-10, 1 - 1e-10)) {
rootfinding <- function(pi1, delta, alpha, lambda0, pi0, lambda1) {
tmp <- fdelta(alpha, lambda0, pi0, lambda1, pi1)
#cat("tmp:", tmp, "pi1:", pi1, "\n")
delta - tmp
}
uniroot(rootfinding, interval = interval, delta = delta,
alpha = alpha,
lambda0 = lambda0, lambda1 = lambda1, pi0 = pi0)$root
}
#' simulate realizations using INAR(3) with zero-inflated Poisson innovation and one sustained shift
#'
#' @param n is the length
#' @param alpha is the alpha
#' @param lambda is the mean of poisson mixture
#' @param pi is the proportion of zeros
#' @param h is the start point of shift
#' @param delta is the value of the standardized shift
#' @param burnin is the length of the burn-in period
#' @export
#' @examples
#' nsim <- 100
#' burnin <- 100
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' alpha <- c(0.03083069, 0.06242601, 0.09120189)
#' lambda <- 0.239385
#' pi <- 0.1453097
#'
#' TT <- 183
#' w <- 28
#' Y <- rzinpoisinar3(TT + w, alpha, lambda, pi, ceiling(TT / 2) + w, delta = 1, burnin = burnin)
#'
rzinpoisinar3 <- function(n, alpha, lambda, pi, h, delta, burnin = 100) {
q <- length(alpha)
out <- rep(NA, n + burnin + q)
out[1:q] <- VGAM::rzipois(q, lambda, pi)
k <- 0
lambda1 <- flambda1(delta, alpha, lambda, pi, pi1 = pi, interval = c(1e-10, 1000))
for (i in (q + 1):(n + burnin + q)) {
for (j in 1:q) {
out[i] <- rbinom(1, out[i - j], alpha[j])
}
if (i >= (q + 1 + burnin)) {
k <- k + 1
}
if (k >= h) {
out[i] <- out[i] + VGAM::rzipois(1, lambda1, pi)
} else {
out[i] <- out[i] + VGAM::rzipois(1, lambda, pi)
}
}
out[(burnin + q + 1):(n + burnin + q)]
}
w <- 14
Y <- rzinpoisinar3(n = 183 + w, alpha = c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.5, h = 92, delta = 1, burnin = 100)
debug(rzinpoisinar3)
Y <- rzinpoisinar3(n = 183 + w, alpha = c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.5, h = 92, delta = 1, burnin = 100)
w <- 14
debug(rzinpoisinar3)
Y <- rzinpoisinar3(n = 183 + w, alpha = c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.2, h = 92, delta = 1, burnin = 100)
Y
undebug(rzinpoisinar3)
movaver <- function(x, n = 5){filter(x, rep(1 / n, n), sides = 1)}
remove.packages("BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
Rcpp::compileAttributes()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
devtools::install_github("bolus123/BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
w <- 28
TT <- 183
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w, c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.2, h = 92, delta = 1)
Y
?BayesianLASSOMonitoring::GibbsRFLSM.count
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
debug(BayesianLASSOMonitoring::GibbsRFLSM.count)
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
debug(BayesianLASSOMonitoring::GibbsRFLSM.count)
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
H
H
H
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
? BayesianLASSOMonitoring::getHMatMT
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
w <- 28
TT <- 183
q <- 5
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w, c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.2, h = 92, delta = 1)
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
H
undebug(BayesianLASSOMonitoring::GibbsRFLSM.count)
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
model
model$fit.tr
model$fit
dim(model$fit)
model$fit[, 1]
model$fit[, 2]
model$fit[, 3]
model$fit[, 4]
model$fit[, 5]
fit0 <- BayesianLASSOMonitoring::Fit0(Y, model$Phi, model$muq)
fit0
fit0[1, ]
model$Y.tr
#' Random Flexible Level Shift Model
#'
#' gets a posterior sample using Gibbs sampling for Random Flexible Level Shift Model
#' @param Y is a vector.
#' @param H is the design matrix for shifts.
#' @param X is the input matrix
#' @param q is the number of lags.
#' @param A is a given variance-covariance matrix in MT and regression for the slab-and-spike coefficients.
#' @param a is a given shape of the prior gamma distribution for sigma2.
#' @param b is a given scale of the prior gamma distribution for sigma2.
#' @param alpha is a given shape of the prior gamma distribution for lambda2.
#' @param beta is a given scale of the prior gamma distribution for lambda2.
#' @param theta1 is a given shape1 of the prior beta distribution for the probability of Tau and Kappa.
#' @param theta2 is a given shape2 of the prior beta distribution for the probability of Tau and Kappa.
#' @param xi2 is a given variance of the prior normal distribution for shifts.
#' @param method is a choice of methods including MT(McCulloch-Tsay), regression, LASSO, ALASSO(Adaptive LASSO), MonoLASSO(LASSO with Monotonicity constrains), MonoALASSO(Adaptive LASSO with Monotonicity constrains).
#' @param bound0 is an upper bound of the methods with Monotonicity constrains.
#' @param boundqplus1 is  a lower bound of the methods with Monotonicity constrains.
#' @param nsim is the number of draws from MCMC.
#' @param by is the interval of systematic sampling for the draws from MCMC.
#' @param burnin is the length of burn-in period.
#' @param tol is the tolerance level.
#' @references McCulloch, R. E., & Tsay, R. S. (1993). Bayesian inference and prediction for mean and variance shifts in autoregressive time series. Journal of the american Statistical association, 88(423), 968-978.
#'
#'
#' @export
#' @examples
#' nsim <- 100
#' burnin <- 100
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM(Y, H = H, q = q, nsim = nsim, burnin = burnin)
#'
GibbsRFLSM <- function(Y, H = NULL, X = NULL, q = 5,
A = diag(nrow = q + ifelse(is.null(X), 0, dim(X)[2])),
a = 0.1, b = 0.1, alpha = 0.1, beta = 0.1,
theta1 = 1, theta2 = 1, xi2 = 0.1,
method = "MonoALASSO", bound0 = Inf, boundqplus1 = 0,
nsim = 1000, by = 1, burnin = 1000, tol = 1e-10) {
TT <- length(Y)
if (is.null(H) && is.null(X)) {
model <- GibbsRFLSMcpp(Y, q,
A, a, b, alpha, beta,
theta1, theta2, xi2,
method, bound0, boundqplus1,
nsim, by, burnin,
tol)
} else {
H1 <- cbind(H, X)
model <- GibbsRFLSMcpp(Y, q,
A, a, b, alpha, beta,
theta1, theta2, xi2,
method, bound0, boundqplus1,
nsim, by, burnin,
tol, H1)
}
if (is.null(H)) {
m <- 0
Gamma <- NA
Tau <- NA
pGamma <- NA
} else {
m <- dim(H)[2]
Gamma <- model$Gamma[1:m, ]
Tau <- model$Tau[1:m, ]
pGamma <- model$p[1:m, ]
}
if (is.null(X)) {
p <- 0
Beta <- NA
Kappa <- NA
pBeta <- NA
} else {
p <- dim(X)[2]
Beta <- model$Gamma[(m + 1):(m + p), ]
Kappa <- model$Tau[(m + 1):(m + p), ]
pBeta <- model$p[(m + 1):(m + p), ]
}
fit <- matrix(NA, nrow = TT, ncol = nsim)
resi <- matrix(NA, nrow = TT, ncol = nsim)
stdresi <- matrix(NA, nrow = TT, ncol = nsim)
for (i in 1:nsim) {
fit[, i] <- model$Mu[, i]
tmpresi <- Y - model$Mu[, i]
tmpV <- getV(tmpresi, q)
V <- tmpV[-c(1:q), ]
fit[(q + 1):TT, i] <- fit[(q + 1):TT, i] + V %*% model$Phi[, i]
resi[, i] <- Y - fit[, i]
}
out <- list(
"Phi" = model$Phi,
"Beta" = Beta,
"pBeta" = pBeta,
"Kappa" = Kappa,
"Gamma" = Gamma,
"pGamma" = pGamma,
"Tau" = Tau,
"sigma2" = model$sigma2,
"lambda2" = model$lambda2,
"muq" = model$muq,
"Mu" = model$Mu,
"fit" = fit,
"resi" = resi
)
return(out)
}
movaver <- function(x, n = 5){filter(x, rep(1 / n, n), sides = 1)}
#' Random Flexible Level Shift Model
#'
#' gets a posterior sample using Gibbs sampling for Random Flexible Level Shift Model
#' @param Y is a vector.
#' @param H is the design matrix for shifts.
#' @param X is the input matrix
#' @param q is the number of lags.
#' @param A is a given variance-covariance matrix in MT and regression for the slab-and-spike coefficients.
#' @param a is a given shape of the prior gamma distribution for sigma2.
#' @param b is a given scale of the prior gamma distribution for sigma2.
#' @param alpha is a given shape of the prior gamma distribution for lambda2.
#' @param beta is a given scale of the prior gamma distribution for lambda2.
#' @param theta1 is a given shape1 of the prior beta distribution for the probability of Tau and Kappa.
#' @param theta2 is a given shape2 of the prior beta distribution for the probability of Tau and Kappa.
#' @param xi2 is a given variance of the prior normal distribution for shifts.
#' @param method is a choice of methods including MT(McCulloch-Tsay), regression, LASSO, ALASSO(Adaptive LASSO), MonoLASSO(LASSO with Monotonicity constrains), MonoALASSO(Adaptive LASSO with Monotonicity constrains).
#' @param bound0 is an upper bound of the methods with Monotonicity constrains.
#' @param boundqplus1 is  a lower bound of the methods with Monotonicity constrains.
#' @param nsim is the number of draws from MCMC.
#' @param by is the interval of systematic sampling for the draws from MCMC.
#' @param burnin is the length of burn-in period.
#' @param tol is the tolerance level.
#' @param logcc is the log transformation
#' @param standardized is the standardization
#' @references McCulloch, R. E., & Tsay, R. S. (1993). Bayesian inference and prediction for mean and variance shifts in autoregressive time series. Journal of the american Statistical association, 88(423), 968-978.
#'
#'
#' @export
#' @examples
#' nsim <- 100
#' burnin <- 100
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM.count(Y, H = H, q = q, nsim = nsim, burnin = burnin)
#'
GibbsRFLSM.count <- function(Y, w = 28, H = NULL, X = NULL, Y0 = rep(mean(Y), w), q = 5,
A = diag(nrow = q + ifelse(is.null(X), 0, dim(X)[2])),
a = 0.1, b = 0.1, alpha = 0.1, beta = 0.1,
theta1 = 1, theta2 = 1, xi2 = 0.1,
method = "MonoALASSO", bound0 = Inf, boundqplus1 = 0,
nsim = 1000, by = 1, burnin = 1000, tol = 1e-10,
logcc = TRUE, standardized = TRUE) {
Y1 <- c(Y0, Y)
####################################
Y1 <- movaver(Y1, w)[-c(1:w)]
Y0 <- Y1
####################################
if (logcc == TRUE) {
Y1 <- log(Y1 + 0.5)
}
if (standardized == TRUE) {
meanY <- mean(Y1)
sdY <- sd(Y1)
Y1 <- (Y1 - meanY) / sdY
}
model <- GibbsRFLSM(Y1, H, X, q,
A,
a, b, alpha, beta,
theta1, theta2, xi2,
method, bound0, boundqplus1,
nsim, by, burnin, tol)
fit0 <- model$fit
if (standardized == TRUE) {
fit0 <- fit0 * sdY + meanY
}
if (logcc == TRUE) {
fit0 <- exp(fit0) - 0.5
}
out <- list(
"Phi" = model$Phi,
"Beta" = model$Beta,
"pBeta" = model$pBeta,
"Kappa" = model$Kappa,
"Gamma" = model$Gamma,
"pGamma" = model$pGamma,
"Tau" = model$Tau,
"sigma2" = model$sigma2,
"lambda2" = model$lambda2,
"muq" = model$muq,
"Mu" = model$Mu,
"fit.tr" = model$fit,
"resi.tr" = model$resi,
"Y.tr" = Y1,
"fit.ma" = fit0,
"resi.ma" = matrix(Y0, ncol = nsim, nrow = length(Y)) - fit0,
"Y.ma" = Y0
)
return(out)
}
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
model <- GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
roxygen2::roxygenise()
roxygen2::roxygenise()
remove.packages("BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
remove.packages("BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
?BayesianLASSOMonitoring::rzinpoisinar3
TT <- 183
w <- 28
q <- 5
alpha <- c(0.03, 0.05, 0.1)
lambda <- 0.2
pi <- 0.2
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w - 1, alpha, lambda, pi, h = 92, delta = 1)
Y
dim(Y)
length(Y)
remove.packages("BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
TT <- 183
w <- 28
q <- 5
alpha <- c(0.03, 0.05, 0.1)
lambda <- 0.2
pi <- 0.2
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w - 1, alpha, lambda, pi, h = 92, delta = 1)
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[w:(TT + w - 1)], w = w, H = H, Y0 = Y[1:(w - 1)], q = q)
TT <- 183
w <- 28
q <- 5
alpha <- c(0.03, 0.05, 0.1)
lambda <- 0.2
pi <- 0.2
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w - 1, alpha, lambda, pi, h = 92, delta = 1)
debug(BayesianLASSOMonitoring::GibbsRFLSM.count)
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[w:(TT + w - 1)], w = w, H = H, Y0 = Y[1:(w - 1)], q = q)
Y1
model
model$Y.ma
model$Y.tr
model$fit.ma
model$fit.ma[, 1]
model$fit.ma[, 2]
model$fit.ma[1, 2]
model$fit.ma[1, 2] > 100
plot(model$Y.ma)
points(model$fit.ma[, 1])
points(model$fit.ma[, 1], col = 'red')
points(model$fit.ma[, 2], col = 'red')
plot(model$Y.ma, type = 'l')
points(model$fit.ma[, 1], col = 'red')
points(model$fit.ma[, 2], col = 'red')
Y[1:(w - 1)]
model$fit.ma
w <- 28
w - (w - 1)
i <- 1
w - 1 + i - 1
w - 1 + i - w + 1
remove.packages("BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
w <- 28
TT <- 183
q <- 5
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w, c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.2, h = 92, delta = 1)
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
debug(BayesianLASSOMonitoring::GibbsRFLSM.count)
model <- GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
w <- 28
TT <- 183
q <- 5
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w, c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.2, h = 92, delta = 1)
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
debug(BayesianLASSOMonitoring::GibbsRFLSM.count)
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
w <- 28
TT <- 183
q <- 5
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w, c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.2, h = 92, delta = 1)
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
debug(BayesianLASSOMonitoring::GibbsRFLSM.count)
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
remove.packages("BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
w <- 28
TT <- 183
q <- 5
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w, c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.2, h = 92, delta = 1)
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
debug(BayesianLASSOMonitoring::GibbsRFLSM.count)
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
sum(YY[w - 1 + i - 1, (w - 1) + i -
(w - 1)])
sum(YY[w - 1 + i - 1, (w - 1) + i -
(w - 1)])
remove.packages("BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
w <- 28
TT <- 183
q <- 5
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w, c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.2, h = 92, delta = 1)
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
debug(BayesianLASSOMonitoring::GibbsRFLSM.count)
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
fit0 <- BayesianLASSOMonitoring::Fit0(Y, model$Phi, model$muq)
w <- 28
TT <- 183
q <- 5
Y <- BayesianLASSOMonitoring::rzinpoisinar3(TT + w, c(0.03, 0.05, 0.1), lambda = 0.2, pi = 0.2, h = 92, delta = 1)
H <- BayesianLASSOMonitoring::getHMatMT(TT, q)
debug(BayesianLASSOMonitoring::GibbsRFLSM.count)
model <- BayesianLASSOMonitoring::GibbsRFLSM.count(Y[-c(1:w)], w, H = H, Y0 = Y[c(1:w)], q = q)
c
remove.packages("BayesianLASSOMonitoring")
devtools::install_github("bolus123/BayesianLASSOMonitoring")
