findAdjustAlpha <- function(sim0, FAP0 = 0.2, interval = c(0.51, 1), tol = 1e-6) {
findroot <- function(cc, sim0, m, FAP0 = 0.2) {
c1 <- cc
c2 <- 1 - cc
quant <- matrix(NA, nrow = m, ncol = 2)
for (i in seq(m)) {
tmp <- quantile(sim0[i, ], c(c2, c1))
quant[i, ] <- tmp
}
tmp <- colSums(quant[, 1] <= sim0 & sim0 <= quant[, 2]) != m
tmp <- mean(tmp)
out <- FAP0 - tmp
cat("c:", cc, "out:", out, "FAP:", tmp, "\n")
out
}
m <- dim(sim0)[1]
uniroot(findroot, interval = interval, sim0 = sim0, m = m, FAP0 = FAP0, tol = tol)$root
}
TT <- length(Y)
nn <- length(muq)
F0 <- Fit(Y, Phi,
matrix(rep(muq, each = TT), nrow = TT, ncol = nn))
sim0 <- matrix(NA, nrow = TT, ncol = nsim)
for (i in seq(nsim)) {
k1 <- sample(seq(nn), 1)
sim0[, i] <- rnorm(TT, F0[, k1], sqrt(mo01$sigma2[k1]))
}
adjalpha <- findAdjustAlpha(sim0, FAP0, interval, tol)
f0bound <- matrix(NA, nrow = nn, ncol = 2)
for (i in seq(TT)) {
f0bound[i, ] <- quantile(sim0[i, ], c(1 - adjalpha, adjalpha))
}
list(
"lowerbound" = f0bound[, 1],
"upperbound" = f0bound[, 2],
"sig" = any((Y < f0bound[, 1]) | (f0bound[, 2] < Y))
)
}
CompResamp(Y1, mo11$Phi, mo11$muq)
debug(CompResamp)
CompResamp(Y1, mo11$Phi, mo11$muq)
.
CompResamp(Y1, mo11$Phi, mo11$muq)
#' get the P value for RFLSM with kernel smoothing
#'
#' @param TauGamma is the distributions of shifts.
#' @param tail is type of the test.
getPvalueKSRFLSM <- function(TauGamma, tail = "2-sided") {
tmp <- TauGamma
nn <- dim(tmp)[1]
pvalue <- rep(0, nn)
for (i in 1:nn) {
tmpkde <- density(tmp[i, ])
rtmpdens <- spatstat.explore::CDF(tmpkde)
tmpp <- rtmpdens(0)
if (tail == "2-sided") {
pvalue[i] <- 2 * min(1 - tmpp, tmpp)
} else if (tail == "left-sided") {
pvalue[i] <- tmpp
} else if (tail == "right-sided") {
pvalue[i] <- 1 - tmpp
}
}
return(pvalue)
}
#' get the P value for RFLSM
#'
#' @param TauGamma is the distributions of shifts.
#' @param tail is type of the test.
getPvalueRFLSM <- function(TauGamma, tail = "2-sided") {
tmp <- TauGamma
nn <- dim(tmp)[1]
pvalue <- rep(0, nn)
for (i in 1:nn) {
if (tail == "2-sided") {
pvalue[i] <- 2 * min(mean(tmp[i, ] < 0), mean(tmp[i, ] > 0))
} else if (tail == "left-sided") {
pvalue[i] <- mean(tmp[i, ] < 0)
} else if (tail == "right-sided") {
pvalue[i] <- mean(tmp[i, ] > 0)
}
}
return(pvalue)
}
#' get a vector of p values
#'
#' @param TauGamma is the distributions of shifts.
#' @param tail is type of the test.
#' @param method get p values with or without kernel smoothing.
#' @export
#' @examples
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM(Y, q, diag(nrow = q), 0.1, 0.1, 0.1, 0.1,
#' 1, 1, 0.1, "MonoALASSO", Inf, 0, 1000, 1, 100, 1e-10, H)
#'
#' getPvalue(result$Tau * result$Gamma)
getPvalue <- function(TauGamma, tail = "2-sided", method = "raw") {
if (method == "raw") {
pvalue <- getPvalueRFLSM(TauGamma, tail)
} else if (method == "ks") {
pvalue <- getPvalueKSRFLSM(TauGamma, tail)
}
pvalue
}
#' caculate posterior predictve pvalue
#'
#' @param Y is Y
#' @param Phi is the lagged coefficients.
#' @param Mu is the individual means
#' @param TauGamma is the distributions of shifts.
#' @param sigma2 is the variance of errors.
#' @param muq is the intercept.
#' @param method is the method to estimate the parameters.
#' @param nsim is the number of simulation for the simulation
#' @export
#' @examples
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM(Y, q, diag(nrow = q), 0.1, 0.1, 0.1, 0.1,
#' 1, 1, 0.1, "MonoALASSO", Inf, 0, 1000, 1, 100, 1e-10, H)
#'
#' PPP(Y0, result$Phi, result$Mu, H, result$Tau * result$Gamma, result$sigma2, result$muq)
#'
PPP <- function(Y, Phi, Mu, H, TauGamma, sigma2, muq, method = "median", nsim = 3000) {
nnsim <- dim(Phi)[2]
q <- dim(Phi)[1]
T <- length(Y)
m <- T - q
YSim <- matrix(NA, nrow = T, ncol = nsim)
RSS0 <- rep(NA, nsim)
RSS1 <- rep(NA, nsim)
RSS0Sim <- rep(NA, nsim)
RSS1Sim <- rep(NA, nsim)
out <- rep(NA, nsim)
tmpPhi <- matrix(NA, nrow = q)
tmpGamma <- matrix(NA, nrow = m)
tmpMu <- matrix(NA, nrow = T)
if (method == "median") {
tmpmuq <- median(muq)
tmpsigma2 <- median(sigma2)
for (i in 1:q) {
tmpPhi[i, 1] <- median(Phi[i, ])
}
for (i in 1:m) {
tmpGamma[i, 1] <- median(TauGamma[i, ])
}
}
tmpMu <- tmpmuq + H %*% tmpGamma
RSS0 <- RSS(Y, matrix(tmpPhi, ncol = 1),
matrix(tmpmuq, ncol = 1))
RSS1 <- RSS(Y, matrix(tmpPhi, ncol = 1),
matrix(tmpMu, ncol = 1))
for (i in 1:nsim) {
tmpsel <- sample(1:nnsim, 1)
YSim[1:q, i] <- Y[1:q]
for (j in (q + 1):T) {
YSim[j, i] <- Mu[j, tmpsel] +
(YSim[(j - 1):(j - q), i] - Mu[(j - 1):(j - q), tmpsel]) %*% Phi[, tmpsel] +
rnorm(1, sd = sqrt(sigma2[tmpsel]))
}
RSS0Sim[i] <- RSS(YSim[, i], matrix(tmpPhi, ncol = 1),
matrix(tmpmuq, ncol = 1))
RSS1Sim[i] <- RSS(YSim[, i], matrix(tmpPhi, ncol = 1),
matrix(tmpMu, ncol = 1))
}
out <- ((RSS0Sim - RSS1Sim) / tmpsigma2) >=
((RSS0 - RSS1) / tmpsigma2)
mean(out)
}
#' check significance using Sidak Correction
#'
#' @param P is P
#' @param FAP0 is FAP0.
#' @param methodP is methodP
#' @param methodComp is methodComp.
#' @export
#' @examples
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM(Y, q, diag(nrow = q), 0.1, 0.1, 0.1, 0.1,
#' 1, 1, 0.1, "MonoALASSO", Inf, 0, 1000, 1, 100, 1e-10, H)
#'
#' MultiComp(result$p)
#'
MultiComp <- function(P, FAP0 = 0.2, methodP = "median",  methodComp = 'Sidak') {
nnsim <- dim(P)[2]
m <- dim(P)[1]
out <- matrix(NA, nrow = m, ncol = 2)
if (methodComp == "Sidak") {
tmpAlpha <- 1 - (1 - FAP0) ^ (1 / m)
}
for (i in seq(m)) {
if (methodP == "median") {
out[i, 1] <- median(1 - P[i, ])
}
out[i, 2] <- (out[i, 1] <= tmpAlpha)
}
out
}
#' comparison using resampling
#'
#' @param P is P
#' @param FAP0 is FAP0.
#' @param methodP is methodP
#' @param methodComp is methodComp.
#' @export
#' @examples
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM(Y, q, diag(nrow = q), 0.1, 0.1, 0.1, 0.1,
#' 1, 1, 0.1, "MonoALASSO", Inf, 0, 1000, 1, 100, 1e-10, H)
#'
#' MultiComp(result$p)
#'
CompResamp <- function(Y, Phi, muq, FAP0 = 0.2,
interval = c(0.51, 1), nsim = 100000, tol = 1e-6) {
findAdjustAlpha <- function(sim0, FAP0 = 0.2, interval = c(0.51, 1), tol = 1e-6) {
findroot <- function(cc, sim0, m, FAP0 = 0.2) {
c1 <- cc
c2 <- 1 - cc
quant <- matrix(NA, nrow = m, ncol = 2)
for (i in seq(m)) {
tmp <- quantile(sim0[i, ], c(c2, c1))
quant[i, ] <- tmp
}
tmp <- colSums(quant[, 1] <= sim0 & sim0 <= quant[, 2]) != m
tmp <- mean(tmp)
out <- FAP0 - tmp
cat("c:", cc, "out:", out, "FAP:", tmp, "\n")
out
}
m <- dim(sim0)[1]
uniroot(findroot, interval = interval, sim0 = sim0, m = m, FAP0 = FAP0, tol = tol)$root
}
TT <- length(Y)
nn <- length(muq)
F0 <- Fit(Y, Phi,
matrix(rep(muq, each = TT), nrow = TT, ncol = nn))
sim0 <- matrix(NA, nrow = TT, ncol = nsim)
for (i in seq(nsim)) {
k1 <- sample(seq(nn), 1)
sim0[, i] <- rnorm(TT, F0[, k1], sqrt(mo01$sigma2[k1]))
}
adjalpha <- findAdjustAlpha(sim0, FAP0, interval, tol)
f0bound <- matrix(NA, nrow = TT, ncol = 2)
for (i in seq(TT)) {
f0bound[i, ] <- quantile(sim0[i, ], c(1 - adjalpha, adjalpha))
}
list(
"lowerbound" = f0bound[, 1],
"upperbound" = f0bound[, 2],
"sig" = any((Y < f0bound[, 1]) | (f0bound[, 2] < Y))
)
}
CompResamp(Y1, mo11$Phi, mo11$muq)
#' get the P value for RFLSM with kernel smoothing
#'
#' @param TauGamma is the distributions of shifts.
#' @param tail is type of the test.
getPvalueKSRFLSM <- function(TauGamma, tail = "2-sided") {
tmp <- TauGamma
nn <- dim(tmp)[1]
pvalue <- rep(0, nn)
for (i in 1:nn) {
tmpkde <- density(tmp[i, ])
rtmpdens <- spatstat.explore::CDF(tmpkde)
tmpp <- rtmpdens(0)
if (tail == "2-sided") {
pvalue[i] <- 2 * min(1 - tmpp, tmpp)
} else if (tail == "left-sided") {
pvalue[i] <- tmpp
} else if (tail == "right-sided") {
pvalue[i] <- 1 - tmpp
}
}
return(pvalue)
}
#' get the P value for RFLSM
#'
#' @param TauGamma is the distributions of shifts.
#' @param tail is type of the test.
getPvalueRFLSM <- function(TauGamma, tail = "2-sided") {
tmp <- TauGamma
nn <- dim(tmp)[1]
pvalue <- rep(0, nn)
for (i in 1:nn) {
if (tail == "2-sided") {
pvalue[i] <- 2 * min(mean(tmp[i, ] < 0), mean(tmp[i, ] > 0))
} else if (tail == "left-sided") {
pvalue[i] <- mean(tmp[i, ] < 0)
} else if (tail == "right-sided") {
pvalue[i] <- mean(tmp[i, ] > 0)
}
}
return(pvalue)
}
#' get a vector of p values
#'
#' @param TauGamma is the distributions of shifts.
#' @param tail is type of the test.
#' @param method get p values with or without kernel smoothing.
#' @export
#' @examples
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM(Y, q, diag(nrow = q), 0.1, 0.1, 0.1, 0.1,
#' 1, 1, 0.1, "MonoALASSO", Inf, 0, 1000, 1, 100, 1e-10, H)
#'
#' getPvalue(result$Tau * result$Gamma)
getPvalue <- function(TauGamma, tail = "2-sided", method = "raw") {
if (method == "raw") {
pvalue <- getPvalueRFLSM(TauGamma, tail)
} else if (method == "ks") {
pvalue <- getPvalueKSRFLSM(TauGamma, tail)
}
pvalue
}
#' caculate posterior predictve pvalue
#'
#' @param Y is Y
#' @param Phi is the lagged coefficients.
#' @param Mu is the individual means
#' @param TauGamma is the distributions of shifts.
#' @param sigma2 is the variance of errors.
#' @param muq is the intercept.
#' @param method is the method to estimate the parameters.
#' @param nsim is the number of simulation for the simulation
#' @export
#' @examples
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM(Y, q, diag(nrow = q), 0.1, 0.1, 0.1, 0.1,
#' 1, 1, 0.1, "MonoALASSO", Inf, 0, 1000, 1, 100, 1e-10, H)
#'
#' PPP(Y0, result$Phi, result$Mu, H, result$Tau * result$Gamma, result$sigma2, result$muq)
#'
PPP <- function(Y, Phi, Mu, H, TauGamma, sigma2, muq, method = "median", nsim = 3000) {
nnsim <- dim(Phi)[2]
q <- dim(Phi)[1]
T <- length(Y)
m <- T - q
YSim <- matrix(NA, nrow = T, ncol = nsim)
RSS0 <- rep(NA, nsim)
RSS1 <- rep(NA, nsim)
RSS0Sim <- rep(NA, nsim)
RSS1Sim <- rep(NA, nsim)
out <- rep(NA, nsim)
tmpPhi <- matrix(NA, nrow = q)
tmpGamma <- matrix(NA, nrow = m)
tmpMu <- matrix(NA, nrow = T)
if (method == "median") {
tmpmuq <- median(muq)
tmpsigma2 <- median(sigma2)
for (i in 1:q) {
tmpPhi[i, 1] <- median(Phi[i, ])
}
for (i in 1:m) {
tmpGamma[i, 1] <- median(TauGamma[i, ])
}
}
tmpMu <- tmpmuq + H %*% tmpGamma
RSS0 <- RSS(Y, matrix(tmpPhi, ncol = 1),
matrix(tmpmuq, ncol = 1))
RSS1 <- RSS(Y, matrix(tmpPhi, ncol = 1),
matrix(tmpMu, ncol = 1))
for (i in 1:nsim) {
tmpsel <- sample(1:nnsim, 1)
YSim[1:q, i] <- Y[1:q]
for (j in (q + 1):T) {
YSim[j, i] <- Mu[j, tmpsel] +
(YSim[(j - 1):(j - q), i] - Mu[(j - 1):(j - q), tmpsel]) %*% Phi[, tmpsel] +
rnorm(1, sd = sqrt(sigma2[tmpsel]))
}
RSS0Sim[i] <- RSS(YSim[, i], matrix(tmpPhi, ncol = 1),
matrix(tmpmuq, ncol = 1))
RSS1Sim[i] <- RSS(YSim[, i], matrix(tmpPhi, ncol = 1),
matrix(tmpMu, ncol = 1))
}
out <- ((RSS0Sim - RSS1Sim) / tmpsigma2) >=
((RSS0 - RSS1) / tmpsigma2)
mean(out)
}
#' check significance using Sidak Correction
#'
#' @param P is P
#' @param FAP0 is FAP0.
#' @param methodP is methodP
#' @param methodComp is methodComp.
#' @export
#' @examples
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM(Y, q, diag(nrow = q), 0.1, 0.1, 0.1, 0.1,
#' 1, 1, 0.1, "MonoALASSO", Inf, 0, 1000, 1, 100, 1e-10, H)
#'
#' MultiComp(result$p)
#'
MultiComp <- function(P, FAP0 = 0.2, methodP = "median",  methodComp = 'Sidak') {
nnsim <- dim(P)[2]
m <- dim(P)[1]
out <- matrix(NA, nrow = m, ncol = 2)
if (methodComp == "Sidak") {
tmpAlpha <- 1 - (1 - FAP0) ^ (1 / m)
}
for (i in seq(m)) {
if (methodP == "median") {
out[i, 1] <- median(1 - P[i, ])
}
out[i, 2] <- (out[i, 1] <= tmpAlpha)
}
out
}
#' comparison using resampling
#'
#' @param P is P
#' @param FAP0 is FAP0.
#' @param methodP is methodP
#' @param methodComp is methodComp.
#' @export
#' @examples
#' T <- 100
#' q <- 5
#' H <- getHMatMT(T, q)
#' Y <- arima.sim(list(ar = 0.5), n = T)
#'
#' result <- GibbsRFLSM(Y, q, diag(nrow = q), 0.1, 0.1, 0.1, 0.1,
#' 1, 1, 0.1, "MonoALASSO", Inf, 0, 1000, 1, 100, 1e-10, H)
#'
#' MultiComp(result$p)
#'
CompResamp <- function(Y, Phi, muq, FAP0 = 0.2,
interval = c(0.51, 1), nsim = 100000, tol = 1e-6) {
findAdjustAlpha <- function(sim0, FAP0 = 0.2, interval = c(0.51, 1), tol = 1e-6) {
findroot <- function(cc, sim0, m, FAP0 = 0.2) {
c1 <- cc
c2 <- 1 - cc
quant <- matrix(NA, nrow = m, ncol = 2)
for (i in seq(m)) {
tmp <- quantile(sim0[i, ], c(c2, c1))
quant[i, ] <- tmp
}
tmp <- colSums(quant[, 1] <= sim0 & sim0 <= quant[, 2]) != m
tmp <- mean(tmp)
out <- FAP0 - tmp
cat("c:", cc, "out:", out, "FAP:", tmp, "\n")
out
}
m <- dim(sim0)[1]
uniroot(findroot, interval = interval, sim0 = sim0, m = m, FAP0 = FAP0, tol = tol)$root
}
TT <- length(Y)
nn <- length(muq)
F0 <- Fit(Y, Phi,
matrix(rep(muq, each = TT), nrow = TT, ncol = nn))
sim0 <- matrix(NA, nrow = TT, ncol = nsim)
for (i in seq(nsim)) {
k1 <- sample(seq(nn), 1)
sim0[, i] <- rnorm(TT, F0[, k1], sqrt(mo01$sigma2[k1]))
}
adjalpha <- findAdjustAlpha(sim0, FAP0, interval, tol)
f0bound <- matrix(NA, nrow = TT, ncol = 2)
for (i in seq(TT)) {
f0bound[i, ] <- quantile(sim0[i, ], c(1 - adjalpha, adjalpha))
}
list(
"lowerbound" = f0bound[, 1],
"upperbound" = f0bound[, 2],
"IndSig" = (Y < f0bound[, 1]) | (f0bound[, 2] < Y),
"Sig" = any((Y < f0bound[, 1]) | (f0bound[, 2] < Y))
)
}
aa <- CompResamp(Y1, mo11$Phi, mo11$muq)
aa
plot(Y)
plot(Y1)
points(aa$lowerbound)
points(aa$uperbound)
points(aa$uperbound)
points(aa$upperbound)
aa <- CompResamp(Y1, mo11$Phi, mo11$muq)
points(aa$upperbound)
Rcpp::compileAttributes()
roxygen2::roxygenise()
roxygen2::roxygenise()
remove.packages("BayesianLassoMonitoring")
remove.packages("BayesianLassoMonitoring")
roxygen2::roxygenise()
roxygen2::roxygenise()
Rcpp::compileAttributes()
roxygen2::roxygenise()
